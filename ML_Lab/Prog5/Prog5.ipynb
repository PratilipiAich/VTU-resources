{"metadata":{"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import csv\nimport random\nimport math","metadata":{"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def loadcsv(filename):\n\tlines = csv.reader(open(filename, \"r\"));\n\tdataset = list(lines)\n\tfor i in range(len(dataset)):\n       #converting strings into numbers for processing\n\t\tdataset[i] = [float(x) for x in dataset[i]]\n        \n\treturn dataset","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def splitdataset(dataset, splitratio):\n    #67% training size\n\ttrainsize = int(len(dataset) * splitratio);\n\ttrainset = []\n\tcopy = list(dataset);    \n\twhile len(trainset) < trainsize:\n#generate indices for the dataset list randomly to pick ele for training data\n\t\tindex = random.randrange(len(copy));       \n\t\ttrainset.append(copy.pop(index))    \n\treturn [trainset, copy]","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def separatebyclass(dataset):\n\tseparated = {} #dictionary of classes 1 and 0 \n#creates a dictionary of classes 1 and 0 where the values are \n#the instances belonging to each class\n\tfor i in range(len(dataset)):\n\t\tvector = dataset[i]\n\t\tif (vector[-1] not in separated):\n\t\t\tseparated[vector[-1]] = []\n\t\tseparated[vector[-1]].append(vector)\n\treturn separated","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def mean(numbers):\n\treturn sum(numbers)/float(len(numbers))","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def stdev(numbers):\n\tavg = mean(numbers)\n\tvariance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n\treturn math.sqrt(variance)","metadata":{"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def summarize(dataset): #creates a dictionary of classes\n\tsummaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)];\n\tdel summaries[-1] #excluding labels +ve or -ve\n\treturn summaries","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def summarizebyclass(dataset):\n\tseparated = separatebyclass(dataset); \n    #print(separated)\n\tsummaries = {}\n\tfor classvalue, instances in separated.items(): \n#for key,value in dic.items()\n#summaries is a dic of tuples(mean,std) for each class value        \n\t\tsummaries[classvalue] = summarize(instances) #summarize is used to cal to mean and std\n\treturn summaries","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def calculateprobability(x, mean, stdev):\n\texponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n\treturn (1 / (math.sqrt(2*math.pi) * stdev)) * exponent","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def calculateclassprobabilities(summaries, inputvector):\n\tprobabilities = {} # probabilities contains the all prob of all class of test data\n\tfor classvalue, classsummaries in summaries.items():#class and attribute information as mean and sd\n\t\tprobabilities[classvalue] = 1\n\t\tfor i in range(len(classsummaries)):\n\t\t\tmean, stdev = classsummaries[i] #take mean and sd of every attribute for class 0 and 1 seperaely\n\t\t\tx = inputvector[i] #testvector's first attribute\n\t\t\tprobabilities[classvalue] *= calculateprobability(x, mean, stdev);#use normal dist\n\treturn probabilities","metadata":{"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def predict(summaries, inputvector): #training and test data is passed\n\tprobabilities = calculateclassprobabilities(summaries, inputvector)\n\tbestLabel, bestProb = None, -1\n\tfor classvalue, probability in probabilities.items():#assigns that class which has he highest prob\n\t\tif bestLabel is None or probability > bestProb:\n\t\t\tbestProb = probability\n\t\t\tbestLabel = classvalue\n\treturn bestLabel","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def getpredictions(summaries, testset):\n\tpredictions = []\n\tfor i in range(len(testset)):\n\t\tresult = predict(summaries, testset[i])\n\t\tpredictions.append(result)\n\treturn predictions","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def getaccuracy(testset, predictions):\n\tcorrect = 0\n\tfor i in range(len(testset)):\n\t\tif testset[i][-1] == predictions[i]:\n\t\t\tcorrect += 1\n\treturn (correct/float(len(testset))) * 100.0","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def main():\n\tfilename = 'naivedata.csv'\n\tsplitratio = 0.67\n\tdataset = loadcsv(filename);\n     \n\ttrainingset, testset = splitdataset(dataset, splitratio)\n\tprint('Split {0} rows into train={1} and test={2} rows'.format(len(dataset), len(trainingset), len(testset)))\n\t# prepare model\n\tsummaries = summarizebyclass(trainingset);    \n\t#print(summaries)\n    # test model\n\tpredictions = getpredictions(summaries, testset) #find the predictions of test data with the training data\n\taccuracy = getaccuracy(testset, predictions)\n\tprint('Accuracy of the classifier is : {0}%'.format(accuracy))","metadata":{"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"main()","metadata":{"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Split 768 rows into train=514 and test=254 rows\nAccuracy of the classifier is : 78.74015748031496%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}